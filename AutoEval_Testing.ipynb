{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8X41_dflK2f"
      },
      "source": [
        "# Table Structure Detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XztZySVglmJ_",
        "outputId": "78b3967f-daff-4902-81ed-1adcac1d63c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0w9GcbTg_97",
        "outputId": "3e456310-0766-4cfd-d440-28ed7693d16f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/NCVPRIPG/table-transformer.zip\n",
            "   creating: content/table-transformer/\n",
            "  inflating: content/table-transformer/README.md  \n",
            "  inflating: content/table-transformer/LICENSE  \n",
            "   creating: content/table-transformer/.github/\n",
            "   creating: content/table-transformer/.github/workflows/\n",
            "  inflating: content/table-transformer/.github/workflows/codeql-analysis.yml  \n",
            "  inflating: content/table-transformer/pubtables1m_structure_detr_r18.pth  \n",
            "   creating: content/table-transformer/src/\n",
            "  inflating: content/table-transformer/src/table_datasets.py  \n",
            "   creating: content/table-transformer/src/datasets/\n",
            "  inflating: content/table-transformer/src/datasets/coco.py  \n",
            "  inflating: content/table-transformer/src/datasets/coco_panoptic.py  \n",
            "   creating: content/table-transformer/src/datasets/__pycache__/\n",
            "  inflating: content/table-transformer/src/datasets/__pycache__/coco_eval.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/datasets/__pycache__/transforms.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/datasets/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/datasets/__pycache__/coco.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/datasets/__pycache__/panoptic_eval.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/datasets/__init__.py  \n",
            "  inflating: content/table-transformer/src/datasets/coco_eval.py  \n",
            "  inflating: content/table-transformer/src/datasets/panoptic_eval.py  \n",
            "  inflating: content/table-transformer/src/datasets/transforms.py  \n",
            "  inflating: content/table-transformer/src/structure_config.json  \n",
            "  inflating: content/table-transformer/src/pubtables1m_structure_detr_r18.pth  \n",
            "  inflating: content/table-transformer/src/engine.py  \n",
            "  inflating: content/table-transformer/src/eval.py  \n",
            "  inflating: content/table-transformer/src/postprocess.py  \n",
            "   creating: content/table-transformer/src/util/\n",
            "  inflating: content/table-transformer/src/util/misc.py  \n",
            "  inflating: content/table-transformer/src/util/box_ops.py  \n",
            "   creating: content/table-transformer/src/util/__pycache__/\n",
            "  inflating: content/table-transformer/src/util/__pycache__/misc.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/util/__pycache__/box_ops.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/util/__pycache__/__init__.cpython-310.pyc  \n",
            " extracting: content/table-transformer/src/util/__init__.py  \n",
            "  inflating: content/table-transformer/src/util/plot_utils.py  \n",
            "   creating: content/table-transformer/src/.ipynb_checkpoints/\n",
            "  inflating: content/table-transformer/src/inference.py  \n",
            "   creating: content/table-transformer/src/__pycache__/\n",
            "  inflating: content/table-transformer/src/__pycache__/postprocess.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/__pycache__/grits.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/__pycache__/table_datasets.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/__pycache__/eval.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/__pycache__/main.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/__pycache__/engine.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/grits.py  \n",
            "  inflating: content/table-transformer/src/detection_config.json  \n",
            "  inflating: content/table-transformer/src/main.py  \n",
            "   creating: content/table-transformer/src/models/\n",
            "  inflating: content/table-transformer/src/models/segmentation.py  \n",
            "  inflating: content/table-transformer/src/models/backbone.py  \n",
            "  inflating: content/table-transformer/src/models/detr.py  \n",
            "  inflating: content/table-transformer/src/models/position_encoding.py  \n",
            "  inflating: content/table-transformer/src/models/matcher.py  \n",
            "  inflating: content/table-transformer/src/models/detr_multi.py  \n",
            "  inflating: content/table-transformer/src/models/transformer.py  \n",
            "   creating: content/table-transformer/src/models/__pycache__/\n",
            "  inflating: content/table-transformer/src/models/__pycache__/position_encoding.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/detr_multi.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/transformer.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/backbone.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/detr.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/matcher.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__pycache__/segmentation.cpython-310.pyc  \n",
            "  inflating: content/table-transformer/src/models/__init__.py  \n",
            "   creating: content/table-transformer/detr/\n",
            "  inflating: content/table-transformer/detr/tox.ini  \n",
            "  inflating: content/table-transformer/detr/README.md  \n",
            "  inflating: content/table-transformer/detr/LICENSE  \n",
            "   creating: content/table-transformer/detr/datasets/\n",
            "  inflating: content/table-transformer/detr/datasets/coco.py  \n",
            "  inflating: content/table-transformer/detr/datasets/coco_panoptic.py  \n",
            "  inflating: content/table-transformer/detr/datasets/__init__.py  \n",
            "  inflating: content/table-transformer/detr/datasets/coco_eval.py  \n",
            "  inflating: content/table-transformer/detr/datasets/panoptic_eval.py  \n",
            "  inflating: content/table-transformer/detr/datasets/transforms.py  \n",
            "  inflating: content/table-transformer/detr/requirements.txt  \n",
            "  inflating: content/table-transformer/detr/engine.py  \n",
            "  inflating: content/table-transformer/detr/test_all.py  \n",
            "   creating: content/table-transformer/detr/d2/\n",
            "  inflating: content/table-transformer/detr/d2/README.md  \n",
            "  inflating: content/table-transformer/detr/d2/converter.py  \n",
            "   creating: content/table-transformer/detr/d2/configs/\n",
            "  inflating: content/table-transformer/detr/d2/configs/detr_256_6_6_torchvision.yaml  \n",
            "  inflating: content/table-transformer/detr/d2/configs/detr_segm_256_6_6_torchvision.yaml  \n",
            "   creating: content/table-transformer/detr/d2/detr/\n",
            "  inflating: content/table-transformer/detr/d2/detr/detr.py  \n",
            "  inflating: content/table-transformer/detr/d2/detr/config.py  \n",
            "  inflating: content/table-transformer/detr/d2/detr/dataset_mapper.py  \n",
            "  inflating: content/table-transformer/detr/d2/detr/__init__.py  \n",
            "  inflating: content/table-transformer/detr/d2/train_net.py  \n",
            "   creating: content/table-transformer/detr/util/\n",
            "  inflating: content/table-transformer/detr/util/misc.py  \n",
            "  inflating: content/table-transformer/detr/util/box_ops.py  \n",
            " extracting: content/table-transformer/detr/util/__init__.py  \n",
            "  inflating: content/table-transformer/detr/util/plot_utils.py  \n",
            "  inflating: content/table-transformer/detr/engine_multi.py  \n",
            "  inflating: content/table-transformer/detr/hubconf.py  \n",
            "  inflating: content/table-transformer/detr/Dockerfile  \n",
            "   creating: content/table-transformer/detr/.circleci/\n",
            "  inflating: content/table-transformer/detr/.circleci/config.yml  \n",
            "  inflating: content/table-transformer/detr/run_with_submitit.py  \n",
            "  inflating: content/table-transformer/detr/main.py  \n",
            "   creating: content/table-transformer/detr/models/\n",
            "  inflating: content/table-transformer/detr/models/segmentation.py  \n",
            "  inflating: content/table-transformer/detr/models/backbone.py  \n",
            "  inflating: content/table-transformer/detr/models/detr.py  \n",
            "  inflating: content/table-transformer/detr/models/position_encoding.py  \n",
            "  inflating: content/table-transformer/detr/models/matcher.py  \n",
            "  inflating: content/table-transformer/detr/models/detr_multi.py  \n",
            "  inflating: content/table-transformer/detr/models/transformer.py  \n",
            "  inflating: content/table-transformer/detr/models/__init__.py  \n",
            "  inflating: content/table-transformer/SECURITY.md  \n",
            "   creating: content/table-transformer/.git/\n",
            "  inflating: content/table-transformer/.git/index  \n",
            "  inflating: content/table-transformer/.git/description  \n",
            "  inflating: content/table-transformer/.git/config  \n",
            "   creating: content/table-transformer/.git/info/\n",
            "  inflating: content/table-transformer/.git/info/exclude  \n",
            "  inflating: content/table-transformer/.git/packed-refs  \n",
            "   creating: content/table-transformer/.git/refs/\n",
            "   creating: content/table-transformer/.git/refs/remotes/\n",
            "   creating: content/table-transformer/.git/refs/remotes/origin/\n",
            " extracting: content/table-transformer/.git/refs/remotes/origin/HEAD  \n",
            "   creating: content/table-transformer/.git/refs/tags/\n",
            "   creating: content/table-transformer/.git/refs/heads/\n",
            "  inflating: content/table-transformer/.git/refs/heads/main  \n",
            "   creating: content/table-transformer/.git/objects/\n",
            "   creating: content/table-transformer/.git/objects/pack/\n",
            "  inflating: content/table-transformer/.git/objects/pack/pack-1cd1af01edc84eb81dbe4a47480ec53e1bd039bb.pack  \n",
            "  inflating: content/table-transformer/.git/objects/pack/pack-1cd1af01edc84eb81dbe4a47480ec53e1bd039bb.idx  \n",
            "   creating: content/table-transformer/.git/objects/info/\n",
            "   creating: content/table-transformer/.git/branches/\n",
            " extracting: content/table-transformer/.git/HEAD  \n",
            "   creating: content/table-transformer/.git/logs/\n",
            "   creating: content/table-transformer/.git/logs/refs/\n",
            "   creating: content/table-transformer/.git/logs/refs/remotes/\n",
            "   creating: content/table-transformer/.git/logs/refs/remotes/origin/\n",
            "  inflating: content/table-transformer/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: content/table-transformer/.git/logs/refs/heads/\n",
            "  inflating: content/table-transformer/.git/logs/refs/heads/main  \n",
            "  inflating: content/table-transformer/.git/logs/HEAD  \n",
            "   creating: content/table-transformer/.git/hooks/\n",
            "  inflating: content/table-transformer/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-commit.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/commit-msg.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-rebase.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/update.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-push.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/pre-receive.sample  \n",
            "  inflating: content/table-transformer/.git/hooks/post-update.sample  \n",
            "   creating: content/table-transformer/docs/\n",
            "  inflating: content/table-transformer/docs/INFERENCE.md  \n",
            "   creating: content/table-transformer/scripts/\n",
            "  inflating: content/table-transformer/scripts/process_fintabnet.py  \n",
            "  inflating: content/table-transformer/scripts/create_padded_dataset.py  \n",
            "  inflating: content/table-transformer/scripts/process_icdar2013.py  \n",
            "  inflating: content/table-transformer/scripts/process_pubmed.py  \n",
            "  inflating: content/table-transformer/scripts/view_annotations.py  \n",
            "  inflating: content/table-transformer/scripts/process_scitsr.py  \n",
            "  inflating: content/table-transformer/SUPPORT.md  \n",
            "  inflating: content/table-transformer/.gitignore  \n",
            "  inflating: content/table-transformer/environment.yml  \n",
            "  inflating: content/table-transformer/CODE_OF_CONDUCT.md  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/NCVPRIPG/table-transformer.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvVPCSNDk-8g",
        "outputId": "4820359a-b766-4693-eb9e-6236a2a6fe4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycocotools (from -r /content/content/table-transformer/detr/requirements.txt (line 2))\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-install-isdec3wj/pycocotools_b8c9690b27ba47a6ba5c3e1d60e03255\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-install-isdec3wj/pycocotools_b8c9690b27ba47a6ba5c3e1d60e03255\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting panopticapi (from -r /content/content/table-transformer/detr/requirements.txt (line 6))\n",
            "  Cloning https://github.com/cocodataset/panopticapi.git to /tmp/pip-install-isdec3wj/panopticapi_f22c76e1fcd745a798205cad0b2f744e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git /tmp/pip-install-isdec3wj/panopticapi_f22c76e1fcd745a798205cad0b2f744e\n",
            "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r /content/content/table-transformer/detr/requirements.txt (line 1)) (3.0.10)\n",
            "Collecting submitit (from -r /content/content/table-transformer/detr/requirements.txt (line 3))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m729.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/content/table-transformer/detr/requirements.txt (line 4)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/content/table-transformer/detr/requirements.txt (line 5)) (0.18.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/content/table-transformer/detr/requirements.txt (line 7)) (1.11.4)\n",
            "Collecting onnx (from -r /content/content/table-transformer/detr/requirements.txt (line 8))\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime (from -r /content/content/table-transformer/detr/requirements.txt (line 9))\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r /content/content/table-transformer/detr/requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.10/dist-packages (from submitit->-r /content/content/table-transformer/detr/requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (3.15.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.6.0->-r /content/content/table-transformer/detr/requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.6.0->-r /content/content/table-transformer/detr/requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->-r /content/content/table-transformer/detr/requirements.txt (line 8)) (3.20.3)\n",
            "Collecting coloredlogs (from onnxruntime->-r /content/content/table-transformer/detr/requirements.txt (line 9))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r /content/content/table-transformer/detr/requirements.txt (line 9)) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->-r /content/content/table-transformer/detr/requirements.txt (line 9)) (24.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (2.8.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->-r /content/content/table-transformer/detr/requirements.txt (line 9))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->-r /content/content/table-transformer/detr/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->-r /content/content/table-transformer/detr/requirements.txt (line 2)) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools, panopticapi\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375636 sha256=b42048dc6fb64ca08c1aa9af95b30104163379c98c0176032af9b848f3f83a33\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_7mnmpm/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "  Building wheel for panopticapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for panopticapi: filename=panopticapi-0.1-py3-none-any.whl size=8260 sha256=96c46b5d768cf71d6d6ac2d556e14c91ee89e3d032a6038e24d8613d59ffff30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_7mnmpm/wheels/70/87/ae/5c2b138c967549070e3fe35f3b5fcaf1ed56e9f5483a09ee65\n",
            "Successfully built pycocotools panopticapi\n",
            "Installing collected packages: submitit, panopticapi, onnx, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, pycocotools, onnxruntime, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.8\n",
            "    Uninstalling pycocotools-2.0.8:\n",
            "      Successfully uninstalled pycocotools-2.0.8\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnx-1.16.1 onnxruntime-1.18.0 panopticapi-0.1 pycocotools-2.0 submitit-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/content/table-transformer/detr/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwYGp9ATlAk6",
        "outputId": "789f7c76-bd71-4572-fc35-c1348c3107b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.6-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.6 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.6 pymupdf-1.24.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/drive/MyDrive/NCVPRIPG/Copy of Sample_Data.zip'"
      ],
      "metadata": {
        "id": "10aBzdhGmQcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwOslakmpCK3"
      },
      "source": [
        "**Create a directory containing all the images on which you intend to find the score.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJK3U_NMqCgz"
      },
      "outputs": [],
      "source": [
        "# Define the folders\n",
        "image_folder = '/content/drive/MyDrive/phase_1_eval_dataset'  # Replace with your images folder path\n",
        "json_folder = '/content/TaTr output'  # Replace with your JSON files folder path\n",
        "output_folder = '/content/Inference'  # Replace with your desired output folder path\n",
        "rotation_folder = '/content/Rotation' # Store images to be rotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gxz7oditlCkC",
        "outputId": "aed387ec-1e22-44f7-8c82-044364974604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image_dir': '/content/drive/MyDrive/phase_1_eval_dataset', 'words_dir': None, 'out_dir': '/content/TaTr output', 'mode': 'recognize', 'structure_config_path': '/content/content/table-transformer/src/structure_config.json', 'structure_model_path': '/content/drive/MyDrive/NCVPRIPG/pubtables1m_structure_detr_r18.pth', 'detection_config_path': None, 'detection_model_path': None, 'detection_device': 'cuda', 'structure_device': 'cuda', 'crops': False, 'objects': True, 'cells': False, 'html': False, 'csv': False, 'verbose': False, 'visualize': False, 'crop_padding': 10}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Creating inference pipeline\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 85.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structure model initialized.\n",
            "Structure model weights loaded.\n",
            "(1/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(2/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(3/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(4/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(5/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(6/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(7/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(8/638)\n",
            "Image loaded.\n",
            "Table(s) recognized.\n",
            "(9/638)\n",
            "Image loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "output with shape [1, 1000, 701] doesn't match the broadcast shape [3, 1000, 701]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/content/table-transformer/src/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/content/table-transformer/src/inference.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'recognize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             extracted_table = pipe.recognize(img, tokens, out_objects=args.objects, out_cells=args.csv,\n\u001b[0m\u001b[1;32m    914\u001b[0m                                 out_html=args.html, out_csv=args.csv)\n\u001b[1;32m    915\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Table(s) recognized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/content/table-transformer/src/inference.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, img, tokens, out_objects, out_cells, out_html, out_csv)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;31m# Transform the image how the model expects it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Run input image through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 1000, 701] doesn't match the broadcast shape [3, 1000, 701]"
          ]
        }
      ],
      "source": [
        "%run -i '/content/content/table-transformer/src/inference.py' --mode recognize --structure_config_path '/content/content/table-transformer/src/structure_config.json' --structure_model_path '/content/drive/MyDrive/NCVPRIPG/pubtables1m_structure_detr_r18.pth' --structure_device cuda --image_dir '/content/drive/MyDrive/phase_1_eval_dataset' --out_dir '/content/TaTr output' -o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGwaoyFcSXwo"
      },
      "source": [
        "Using the Output folder which contains the inference from the table transformer. Let's draw all the bounding boxes using the respective json file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7dfUxVTe0T"
      },
      "source": [
        "But since we only need the T/F column. Let's make bounding boxes for them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "TygJspDMTmyI",
        "outputId": "0ef08774-ddc5-4cf8-af94-7461c770fbb2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Sample_Data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/content/table-transformer/src/inference.py\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m# Process images and JSON files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0monly_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/content/table-transformer/src/inference.py\u001b[0m in \u001b[0;36monly_columns\u001b[0;34m(image_folder, json_folder, output_folder, rotation_folder)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# List all image files in the image folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Sample_Data'"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def only_columns(image_folder, json_folder, output_folder, rotation_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    deleteFlag = False\n",
        "\n",
        "    if image_folder==rotation_folder:\n",
        "        deleteFlag = True\n",
        "\n",
        "    # List all image files in the image folder\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for image_file in image_files:\n",
        "        count+=1\n",
        "\n",
        "\n",
        "        # Construct the full image path\n",
        "        image_path = os.path.join(image_folder, image_file)\n",
        "        # Construct the corresponding JSON file path\n",
        "        json_file = os.path.splitext(image_file)[0] + '_objects.json'\n",
        "        json_path = os.path.join(json_folder, json_file)\n",
        "\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f'Warning: JSON file for {image_file} not found. Skipping.')\n",
        "            continue\n",
        "\n",
        "        # Load the image\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Load the JSON data\n",
        "        with open(json_path, 'r') as f:\n",
        "            json_data = json.load(f)\n",
        "\n",
        "        # Find table columns in JSON data\n",
        "        table_columns = [item for item in json_data if item['label'] == 'table column']\n",
        "\n",
        "        itr = 1\n",
        "        x = 10000\n",
        "        column_tf = None\n",
        "        while x>4000:\n",
        "            x = table_columns[-itr]['bbox'][0]\n",
        "            if x<4000:\n",
        "                break\n",
        "            w = table_columns[-itr]['bbox'][2] - x\n",
        "            #print(x,w)\n",
        "            if x<6000 and w>500 and w<2000:\n",
        "                column_tf = table_columns[-itr]\n",
        "            itr+=1\n",
        "        if not column_tf:\n",
        "            print(f'Warning: No column with bbox[0] > 4000 found in {image_file}. Skipping.')\n",
        "            print(table_columns)\n",
        "            output_path = os.path.join(rotation_folder, image_file)\n",
        "            if not os.path.exists(rotation_folder):\n",
        "              try:\n",
        "                  os.makedirs(rotation_folder)\n",
        "                  print(f\"The folder '{rotation_folder}' was created successfully.\")\n",
        "              except Exception as e:\n",
        "                  print(f\"Error: Unable to create the folder '{rotation_folder}'. {e}\")\n",
        "            print(output_path)\n",
        "            cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "            #plt.imshow(image)\n",
        "            #plt.show()\n",
        "            continue\n",
        "\n",
        "        # Get the bounding box of the selected column\n",
        "        bbox = column_tf['bbox']\n",
        "\n",
        "        # Convert bbox to integer values and expand by 50 pixels\n",
        "        x1, y1, x2, y2 = map(int, bbox)\n",
        "        x1 = max(0, x1 - 200)\n",
        "        y1 = max(0, y1 - 400)\n",
        "        x2 = min(image.shape[1], x2 + 350)\n",
        "        y2 = min(image.shape[0], y2)\n",
        "\n",
        "        # Crop the image to the bounding box\n",
        "        cropped_image = image[y1:y2, x1:x2]\n",
        "\n",
        "        # Save the cropped image to the output folder\n",
        "        if deleteFlag:\n",
        "            os.remove(image_path)\n",
        "        output_path = os.path.join(output_folder, image_file)\n",
        "        cv2.imwrite(output_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
        "        print(f'Processed and saved {image_file}, File: {count}/{len(image_files)}')\n",
        "\n",
        "\n",
        "# Define the folders\n",
        "image_folder = '/content/Sample_Data'  # Replace with your images folder path\n",
        "json_folder = '/content/TaTr output'  # Replace with your JSON files folder path\n",
        "output_folder = '/content/Inference_Columns_Eval'  # Replace with your desired output folder path\n",
        "rotation_folder = '/content/Rotation'\n",
        "\n",
        "# Process images and JSON files\n",
        "only_columns(image_folder, json_folder, output_folder, rotation_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we are unable to find the T/F Column in the original image, we send it to a folder where we rotate the image 3 times and try to get inference on it"
      ],
      "metadata": {
        "id": "5zo9nZ5JuHB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folders\n",
        "image_folder = '/content/Rotation'  # Replace with your images folder path\n",
        "json_folder = '/content/TaTr output'  # Replace with your JSON files folder path\n",
        "output_folder = '/content/Inference_Columns'  # Replace with your desired output folder path\n",
        "\n",
        "for _ in range(3):\n",
        "\n",
        "  for filename in os.listdir(image_folder):\n",
        "        file_path = os.path.join(image_folder, filename)\n",
        "\n",
        "        # Check if the file is an image (you can add more extensions if needed)\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "            try:\n",
        "                # Read the image\n",
        "                image = cv2.imread(file_path)\n",
        "\n",
        "                # Rotate the image by 90 degrees clockwise\n",
        "                rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "                #plt.imshow(rotated_image)\n",
        "                #plt.show()\n",
        "\n",
        "                # Overwrite the original image with the rotated image\n",
        "                cv2.imwrite(file_path, rotated_image)\n",
        "\n",
        "                print(f\"Rotated {filename} and saved.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {filename}: {e}\")\n",
        "\n",
        "  %run -i '/content/content/table-transformer/src/inference.py' --mode recognize --structure_config_path '/content/content/table-transformer/src/structure_config.json' --structure_model_path '/content/drive/MyDrive/NCVPRIPG/pubtables1m_structure_detr_r18.pth' --structure_device cuda --image_dir '/content/Rotation' --out_dir '/content/TaTr output' -o\n",
        "\n",
        "  only_columns(image_folder, json_folder, output_folder, rotation_folder)\n"
      ],
      "metadata": {
        "id": "xUeTI3xqc8mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAgD94PcUHkf"
      },
      "source": [
        "# OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ajh-t8HUMvW",
        "outputId": "bfbe7356-0d09-4dfd-c563-a78bd1856442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.6.18)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96Qp8YyjUQlL"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import easyocr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rnp7P__0V12A"
      },
      "outputs": [],
      "source": [
        "score_assignment = {'t': 0.4,\n",
        "                    'r': 0.3,\n",
        "                    'u': 0.3,\n",
        "                    'f': -0.3,\n",
        "                    'a': -0.25,\n",
        "                    'l': -0.25,\n",
        "                    's': -0.2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lmmERtPhsvw"
      },
      "outputs": [],
      "source": [
        "answer1 = pd.read_csv('/content/drive/MyDrive/NCVPRIPG/Phase-1 Evaluation Dataset/model_answer_type1.csv').dropna()\n",
        "answer1 = list(answer1['Correct Answer'].astype(str))\n",
        "mode = max(set(answer1), key=answer1.count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer2 = pd.read_csv('/content/drive/MyDrive/NCVPRIPG/Phase-1 Evaluation Dataset/model_answer_type2.csv').dropna()\n",
        "answer2 = list(answer2['Correct Answer'].astype(str))"
      ],
      "metadata": {
        "id": "kDKpkP0o5Gki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = pd.read_csv('/content/drive/MyDrive/NCVPRIPG/Phase-1 Evaluation Dataset/img_model_answer_mapping.csv')\n",
        "\n",
        "type1 = []\n",
        "type2 = []\n",
        "\n",
        "for i in range(len(mapping)):\n",
        "    if mapping.iloc[i]['model_answer']=='model_answer_type1':\n",
        "        type1.append(mapping.iloc[0]['img_name'])\n",
        "    else:\n",
        "        type2.append(mapping.iloc[0]['img_name'])\n",
        "\n",
        "len(type1), len(type2)"
      ],
      "metadata": {
        "id": "QbDCFGF26NoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/NCVPRIPG/Phase-1 Evaluation Dataset/submission.csv')"
      ],
      "metadata": {
        "id": "58deeUcS7bdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arWut7ClUzOS"
      },
      "outputs": [],
      "source": [
        "# Initialize the OCR reader\n",
        "reader = easyocr.Reader(['en'], detector=True)\n",
        "\n",
        "# Define the whitelist of characters\n",
        "whitelist = 'TRUFALSEtrufalse'\n",
        "\n",
        "def filter_text(text):\n",
        "    # Remove any characters not in the whitelist\n",
        "    filtered_text = ''.join(char for char in text if char in whitelist)\n",
        "    return filtered_text\n",
        "\n",
        "# Specify the folder path containing the images\n",
        "folder_path = '/content/Inference_Columns_Eval'\n",
        "\n",
        "# Keeping Record\n",
        "filenames = []\n",
        "marks_stored = {}\n",
        "count = 0\n",
        "\n",
        "# Iterate over the files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "\n",
        "\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith(('.jpg', '.png', '.bmp')):\n",
        "        # Construct the full file path\n",
        "        count+=1\n",
        "\n",
        "        if filename in type1:\n",
        "            answers = answer1\n",
        "        else:\n",
        "            answers = answer2\n",
        "\n",
        "\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Load the image\n",
        "        image = mpimg.imread(file_path)\n",
        "\n",
        "        # Perform OCR and extract text\n",
        "        result = reader.readtext(image)\n",
        "\n",
        "\n",
        "        flag_header = True\n",
        "\n",
        "        question_no = 0\n",
        "        marks = 0\n",
        "\n",
        "        # Sorting Result based on y-coordinate of top-left corner of bounding boxes\n",
        "        result = sorted(result, key=lambda item: item[0][0][1])\n",
        "\n",
        "\n",
        "        topleftY = []\n",
        "\n",
        "        # Merging close by boxes\n",
        "        for bbox, text, _ in result:\n",
        "            if flag_header:\n",
        "                flag_header = False\n",
        "                continue\n",
        "            filtered_text = filter_text(text)\n",
        "            lowercase_filtered_text = filtered_text.lower()\n",
        "            if (bbox[0][0] < 100) and len(lowercase_filtered_text)<=2 and not (lowercase_filtered_text=='f' or lowercase_filtered_text=='t'):\n",
        "                continue\n",
        "            if lowercase_filtered_text=='' or bbox[0][1]<200:\n",
        "                continue\n",
        "            topleftY.append(bbox[0][1])\n",
        "\n",
        "        temp = topleftY.copy()\n",
        "        skip = False\n",
        "        newResult = []\n",
        "\n",
        "        for i in range(len(temp)-1):\n",
        "            if skip:\n",
        "                skip=False\n",
        "                continue\n",
        "            if temp[i+1]-temp[i]<300:\n",
        "                skip = True\n",
        "                if i==len(temp)-2:\n",
        "                    topleftY.remove(temp[i+1])\n",
        "\n",
        "                else:\n",
        "                    if (temp[i+2]-temp[i+1])<(temp[i+1]-temp[i]):\n",
        "                        topleftY.remove(temp[i+2])\n",
        "\n",
        "                    else:\n",
        "                        topleftY.remove(temp[i+1])\n",
        "\n",
        "        # Making a new result which will contain y coordinate of topleft bbox of all merged boxes and corresponding merged text\n",
        "        resultNew = [None]*len(topleftY)\n",
        "        itr = 0\n",
        "\n",
        "\n",
        "        for i in range(len(temp)):\n",
        "            newText = ''\n",
        "            for bbox, text, _ in result:\n",
        "                if bbox[0][1]==temp[i]:\n",
        "                    newText += filter_text(text)\n",
        "            if itr<len(topleftY) and temp[i]==topleftY[itr]:\n",
        "                if not resultNew[itr]:\n",
        "                    resultNew[itr] = [newText,topleftY[itr]]\n",
        "                else:\n",
        "                    resultNew[itr][0]+=newText\n",
        "                itr+=1\n",
        "            else:\n",
        "                if itr==len(topleftY) or abs(temp[i]-topleftY[itr-1])<abs(temp[i]-topleftY[itr]):\n",
        "                    resultNew[itr-1][0]+=newText\n",
        "                else:\n",
        "                    itr+=1\n",
        "                    resultNew[itr-1]=[newText,topleftY[itr-1]]\n",
        "\n",
        "\n",
        "        # Iterate over the detected text blocks and filter\n",
        "        flag_header = True\n",
        "\n",
        "\n",
        "        # Checking if the case is such where answers are left blank or answers are single T/F predictions\n",
        "        blanks = False\n",
        "        solo = False\n",
        "\n",
        "        if len(resultNew)<10:\n",
        "            for text, _ in resultNew:\n",
        "                if text!='T' and text!='F':\n",
        "                    blanks = True\n",
        "            if not blanks:\n",
        "                solo = True\n",
        "\n",
        "        for i in range(len(resultNew)):\n",
        "\n",
        "            toSkip = 0\n",
        "            toFill = 0\n",
        "\n",
        "            text = resultNew[i][0]\n",
        "            bbox = resultNew[i][1]\n",
        "\n",
        "            # If boxes are left blank, skip the blank box\n",
        "            if blanks and i!=len(resultNew)-1:\n",
        "                if i==0:\n",
        "                    question_no+=max(int((bbox-200)//550),0)\n",
        "                toSkip = int(((resultNew[i+1][1]-resultNew[i][1])//550)-1)\n",
        "\n",
        "            # If single character T/F detected, autofill\n",
        "            if solo and i!=len(resultNew)-1:\n",
        "                if i==0:\n",
        "                    toFill=max(int((bbox-200)//550),0)\n",
        "                    while toFill:\n",
        "                        if (answers[question_no]==mode):\n",
        "                            marks+=1\n",
        "                        #print(f'Fill Prediction: {mode}')\n",
        "                        question_no+=1\n",
        "                        toFill-=1\n",
        "                else:\n",
        "                    toFill=int(((resultNew[i+1][1]-resultNew[i][1])//550)-1)\n",
        "\n",
        "            if solo and i==len(resultNew)-1:\n",
        "                questOG = question_no\n",
        "                question_no+=1\n",
        "                while question_no<10:\n",
        "                    if answers[question_no]==mode:\n",
        "                        marks+=1\n",
        "                    #print(f'Fill Prediction: {mode}')\n",
        "                    question_no+=1\n",
        "                question_no = questOG\n",
        "\n",
        "            score = 0\n",
        "            lowercase_filtered_text = text.lower()\n",
        "            for j in lowercase_filtered_text:\n",
        "                for char in score_assignment:\n",
        "                    if j==char:\n",
        "                        score+=score_assignment[char]\n",
        "            if score>0:\n",
        "                if (answers[question_no] == 'True'):\n",
        "                    marks+=1\n",
        "                #print(f\"File: {filename}, Prediction: True, BBox Top Left: {bbox}\")\n",
        "            else:\n",
        "                if (answers[question_no] == 'False'):\n",
        "                    marks+=1\n",
        "                #print(f\"File: {filename}, Prediction: False, BBox Top Left: {bbox}\")\n",
        "\n",
        "            question_no += 1+max(0,toSkip)\n",
        "\n",
        "            while toFill:\n",
        "                if (answers[question_no]==mode):\n",
        "                    marks+=1\n",
        "                    #print(f'Fill Prediction: {mode}')\n",
        "                question_no+=1\n",
        "                toFill-=1\n",
        "\n",
        "\n",
        "            if (question_no > 9):\n",
        "                break\n",
        "\n",
        "        if not count%100:\n",
        "            print(resultNew)\n",
        "\n",
        "            plt.imshow(image)\n",
        "            plt.title(filename)\n",
        "            plt.show()\n",
        "\n",
        "        submission.loc[submission['img_name'] == filename, 'pred_marks'] = marks\n",
        "\n",
        "        # Update the filename and marks_stored\n",
        "        filenames.append(filename)\n",
        "        marks_stored[filename] = marks\n",
        "        print(f\"{filename} has scores : {marks}, File: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame(marks_stored, index=['Marks']).T.reset_index()\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('output.csv', index=False)"
      ],
      "metadata": {
        "id": "h6TNpnokR_Ea"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}